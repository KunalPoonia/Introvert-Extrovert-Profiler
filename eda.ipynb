{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrovert-Introvert Profiler\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Project Goal:** Find out which behaviors and social habits help us identify if someone is an Extrovert or Introvert.\n",
    "\n",
    "---\n",
    "\n",
    "## Part A: Study the Data\n",
    "## Part B: Data Cleaning\n",
    "## Part C: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART A: STUDY THE DATA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas: Used for data manipulation and analysis (DataFrames)\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: Used for numerical operations on arrays\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib: Used for creating static visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn: Built on matplotlib, provides beautiful statistical plots\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warning messages for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set default figure size for all plots (width=10, height=5 inches)\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "# Set seaborn style to whitegrid for better readability\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print('Libraries loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(): Reads a CSV file and loads it into a DataFrame\n",
    "# DataFrame is like an Excel spreadsheet - rows and columns of data\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# len(data): Returns the number of rows in the DataFrame\n",
    "# len(data.columns): Returns the number of columns\n",
    "print('Dataset has', len(data), 'rows and', len(data.columns), 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: View the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(): Shows the first 5 rows of the DataFrame\n",
    "# Useful to quickly see what the data looks like\n",
    "print('First 5 rows:')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.tail(): Shows the last 5 rows of the DataFrame\n",
    "# Helps verify data loaded completely\n",
    "print('Last 5 rows:')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns.tolist(): Returns all column names as a list\n",
    "print('Column names:')\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# data.shape: Returns (rows, columns) as a tuple\n",
    "# shape[0] = number of rows, shape[1] = number of columns\n",
    "print('\\nRows:', data.shape[0])\n",
    "print('Columns:', data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dtypes: Shows the data type of each column\n",
    "# int64 = integer, float64 = decimal, object = text/string\n",
    "print('Data types:')\n",
    "print(data.dtypes)\n",
    "\n",
    "# data.info(): Shows detailed info - column names, non-null counts, data types, memory usage\n",
    "# Non-null count helps identify missing values\n",
    "print('\\nData Info:')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.describe(): Shows statistical summary for numerical columns\n",
    "# Includes: count, mean, std, min, 25%, 50% (median), 75%, max\n",
    "# Helps understand the distribution and range of values\n",
    "print('Statistics:')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe(include='all'): Shows statistics for ALL columns including categorical\n",
    "# For categorical: shows count, unique values, top (most frequent), freq (frequency of top)\n",
    "print('All columns statistics:')\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isnull(): Returns True/False for each cell (True if missing)\n",
    "# .sum(): Counts True values (missing values) for each column\n",
    "print('Missing values:')\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Calculate missing value percentage for each column\n",
    "# Formula: (missing count / total rows) * 100\n",
    "print('\\nMissing values percentage:')\n",
    "for col in data.columns:\n",
    "    missing = data[col].isnull().sum()\n",
    "    pct = (missing / len(data)) * 100\n",
    "    print(f'{col}: {missing} ({round(pct, 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values as a bar chart\n",
    "# Filter to only show columns with missing values (> 0)\n",
    "missing = data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "# plt.bar(): Creates a bar chart\n",
    "# missing.index = column names, missing.values = counts\n",
    "plt.bar(missing.index, missing.values, color='coral')\n",
    "plt.title('Missing Values')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust spacing to prevent label cutoff\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.duplicated(): Returns True for rows that are duplicates of earlier rows\n",
    "# .sum(): Counts the number of duplicate rows\n",
    "# Duplicates can skew analysis and should be removed\n",
    "dup_count = data.duplicated().sum()\n",
    "print('Duplicate rows:', dup_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Check Categorical Values (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid/inconsistent values in categorical columns\n",
    "# value_counts(): Counts frequency of each unique value\n",
    "# dropna=False: Also shows count of NaN (missing) values\n",
    "# This helps detect typos like 'yes' vs 'Yes' or unexpected values\n",
    "print('Checking categorical values for inconsistencies:')\n",
    "print('\\nStage_fear:')\n",
    "print(data['Stage_fear'].value_counts(dropna=False))\n",
    "print('\\nDrained_after_socializing:')\n",
    "print(data['Drained_after_socializing'].value_counts(dropna=False))\n",
    "print('\\nPersonality:')\n",
    "print(data['Personality'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Class Imbalance Check (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution - important for classification problems\n",
    "# Imbalanced data can cause model to be biased towards majority class\n",
    "print('Class Distribution:')\n",
    "print(data['Personality'].value_counts())\n",
    "\n",
    "# normalize=True: Shows proportions instead of counts (multiply by 100 for %)\n",
    "print('\\nClass Distribution (%):')\n",
    "print(data['Personality'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualize class distribution with bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "data['Personality'].value_counts().plot(kind='bar', color=['steelblue', 'coral'])\n",
    "plt.title('Class Distribution: Extrovert vs Introvert')\n",
    "plt.xlabel('Personality')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate imbalance ratio: majority class / minority class\n",
    "# Ratio > 1.5 indicates imbalance that may need handling\n",
    "counts = data['Personality'].value_counts()\n",
    "ratio = counts.max() / counts.min()\n",
    "print(f'\\nImbalance Ratio: {ratio:.2f}:1')\n",
    "if ratio > 1.5:\n",
    "    print('WARNING: Dataset is imbalanced!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Data Study Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of all findings from Part A\n",
    "# '=' * 40 creates a line of 40 equal signs for visual separation\n",
    "print('=' * 40)\n",
    "print('DATA STUDY SUMMARY')\n",
    "print('=' * 40)\n",
    "print('Rows:', len(data))\n",
    "print('Columns:', len(data.columns))\n",
    "# .sum().sum(): First sum counts per column, second sum totals all columns\n",
    "print('Missing values:', data.isnull().sum().sum())\n",
    "print('Duplicates:', data.duplicated().sum())\n",
    "# Filter rows where Personality equals specific value and count them\n",
    "print('Extroverts:', len(data[data['Personality'] == 'Extrovert']))\n",
    "print('Introverts:', len(data[data['Personality'] == 'Introvert']))\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART B: DATA CLEANING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.copy(): Creates a copy so original data remains unchanged\n",
    "# Always work on a copy when cleaning to preserve raw data\n",
    "clean_data = data.copy()\n",
    "print('Created copy for cleaning!')\n",
    "\n",
    "# List of numerical columns that need missing value handling\n",
    "num_cols = ['Time_spent_Alone', 'Social_event_attendance', \n",
    "            'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
    "\n",
    "# Fill missing numerical values with MEDIAN\n",
    "# Median is preferred over mean because it's not affected by outliers\n",
    "print('\\nFilling numerical columns with MEDIAN:')\n",
    "for col in num_cols:\n",
    "    median = clean_data[col].median()  # Calculate median of non-null values\n",
    "    before = clean_data[col].isnull().sum()  # Count missing before\n",
    "    clean_data[col] = clean_data[col].fillna(median)  # Replace NaN with median\n",
    "    print(f'{col}: {before} -> 0 (median={median})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns that need missing value handling\n",
    "cat_cols = ['Stage_fear', 'Drained_after_socializing']\n",
    "\n",
    "# Fill missing categorical values with MODE (most frequent value)\n",
    "# Mode is the best choice for categorical data\n",
    "print('Filling categorical columns with MODE:')\n",
    "for col in cat_cols:\n",
    "    mode = clean_data[col].mode()[0]  # mode() returns a Series, [0] gets first value\n",
    "    before = clean_data[col].isnull().sum()\n",
    "    clean_data[col] = clean_data[col].fillna(mode)  # Replace NaN with mode\n",
    "    print(f'{col}: {before} -> 0 (mode={mode})')\n",
    "\n",
    "# Verify all missing values are now filled\n",
    "print('\\nMissing values after cleaning:')\n",
    "print(clean_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the dataset\n",
    "before = clean_data.duplicated().sum()\n",
    "\n",
    "# drop_duplicates(): Removes rows that are exact copies of earlier rows\n",
    "# reset_index(drop=True): Resets row numbers to 0,1,2,3... after removal\n",
    "# drop=True prevents old index from being added as a new column\n",
    "clean_data = clean_data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "after = clean_data.duplicated().sum()\n",
    "print('Duplicates before:', before)\n",
    "print('Duplicates after:', after)\n",
    "print('Index reset: Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Drop ID Column (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column - it's just a row identifier, not useful for analysis\n",
    "# Including id in modeling would cause data leakage or meaningless patterns\n",
    "print('Dropping id column...')\n",
    "\n",
    "# drop('id', axis=1): Removes the 'id' column\n",
    "# axis=1 means column (axis=0 would mean row)\n",
    "clean_data = clean_data.drop('id', axis=1)\n",
    "print('Columns:', clean_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Verify Data Ranges (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data ranges are within expected/logical bounds\n",
    "# This helps detect data entry errors (e.g., negative hours, impossible values)\n",
    "print('Verifying data ranges:')\n",
    "for col in num_cols:\n",
    "    # .min() and .max() return the smallest and largest values in the column\n",
    "    print(f'{col}: {clean_data[col].min()} to {clean_data[col].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots to visualize outliers in numerical columns\n",
    "# Box plots show: median (line), quartiles (box), and outliers (dots)\n",
    "\n",
    "# plt.subplots(2, 3): Creates a 2x3 grid of subplots (6 total)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# axes.flatten(): Converts 2D array of axes to 1D for easier looping\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Create a boxplot for each numerical column\n",
    "for i in range(len(num_cols)):\n",
    "    axes[i].boxplot(clean_data[num_cols[i]])\n",
    "    axes[i].set_title(num_cols[i])\n",
    "\n",
    "# Turn off the 6th subplot (we only have 5 columns)\n",
    "axes[5].axis('off')\n",
    "plt.suptitle('Checking Outliers')  # Main title for all subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Final Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the cleaned dataset to verify changes\n",
    "print('Cleaned data:')\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show info of cleaned data to confirm:\n",
    "# - No missing values (all columns show same non-null count)\n",
    "# - id column is removed\n",
    "# - Data types are correct\n",
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary comparing original vs cleaned data\n",
    "# This documents what changes were made during cleaning\n",
    "print('=' * 40)\n",
    "print('CLEANING SUMMARY')\n",
    "print('=' * 40)\n",
    "print('BEFORE:')\n",
    "print('  Rows:', len(data))  # Original row count\n",
    "print('  Columns:', len(data.columns))  # Original column count\n",
    "print('  Missing:', data.isnull().sum().sum())  # Original missing count\n",
    "print('AFTER:')\n",
    "print('  Rows:', len(clean_data))  # May be less if duplicates removed\n",
    "print('  Columns:', len(clean_data.columns), '(dropped id)')  # One less column\n",
    "print('  Missing:', clean_data.isnull().sum().sum())  # Should be 0\n",
    "print('=' * 40)\n",
    "print('DATA IS CLEAN!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17: Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to a new CSV file for use in modeling\n",
    "# to_csv(): Exports DataFrame to a CSV file\n",
    "# index=False: Don't include row numbers in the output file\n",
    "# Uncomment the lines below to save:\n",
    "# clean_data.to_csv('cleaned_data.csv', index=False)\n",
    "# print('Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Part A: Study Data\n",
    "- Loaded train.csv\n",
    "- Viewed data, checked types\n",
    "- Found missing values, checked duplicates\n",
    "- **NEW: Checked categorical values for inconsistencies**\n",
    "- **NEW: Analyzed class imbalance**\n",
    "\n",
    "### Part B: Data Cleaning\n",
    "- Filled numerical with MEDIAN, categorical with MODE\n",
    "- Removed duplicates\n",
    "- **NEW: Reset index after duplicate removal**\n",
    "- **NEW: Dropped id column**\n",
    "- **NEW: Verified data ranges**\n",
    "- Checked outliers\n",
    "\n",
    "### Part C: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART C: DATA VISUALIZATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 18: Time Spent Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot: Compares distribution of Time_spent_Alone between personality types\n",
    "# x-axis: Categories (Extrovert/Introvert)\n",
    "# y-axis: Numerical values (hours spent alone)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Personality', y='Time_spent_Alone', data=clean_data)\n",
    "plt.title('Time Spent Alone by Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Introverts spend MORE time alone (median ~5-6 hours)\n",
    "# Extroverts spend LESS time alone (median ~1-2 hours)\n",
    "# This is a STRONG indicator of personality type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 19: Social Event Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot: Compares social event attendance between personality types\n",
    "# The box shows 25th-75th percentile, line inside is median\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Personality', y='Social_event_attendance', data=clean_data)\n",
    "plt.title('Social Event Attendance by Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Extroverts attend MORE social events (median ~7)\n",
    "# Introverts attend FEWER social events (median ~2)\n",
    "# Clear separation - good predictor feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 20: Going Outside Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot: Compares how often each personality type goes outside\n",
    "# Whiskers extend to 1.5*IQR, points beyond are outliers\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Personality', y='Going_outside', data=clean_data)\n",
    "plt.title('Going Outside Frequency by Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Extroverts go outside MORE often (median ~5)\n",
    "# Introverts go outside LESS often (median ~1-2)\n",
    "# Another strong differentiator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 21: Friends Circle Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot: Compares friend circle size between personality types\n",
    "# Larger box = more variation in the data\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Personality', y='Friends_circle_size', data=clean_data)\n",
    "plt.title('Friends Circle Size by Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Extroverts have MORE friends (median ~10-11)\n",
    "# Introverts have FEWER friends (median ~3-4)\n",
    "# Makes sense - extroverts are more social"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 22: Social Media Post Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot: Compares social media posting frequency\n",
    "# Shows how active each personality type is online\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x='Personality', y='Post_frequency', data=clean_data)\n",
    "plt.title('Social Media Post Frequency by Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Extroverts post MORE on social media (median ~6-7)\n",
    "# Introverts post LESS (median ~2-3)\n",
    "# Extroverts like to share and be visible online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 23: Stage Fear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Shows relationship between Stage_fear and Personality\n",
    "# pd.crosstab(): Creates a frequency table of two categorical variables\n",
    "# Each bar shows count of Extroverts/Introverts for Yes/No stage fear\n",
    "plt.figure(figsize=(8, 4))\n",
    "pd.crosstab(clean_data['Stage_fear'], clean_data['Personality']).plot(kind='bar')\n",
    "plt.title('Stage Fear by Personality')\n",
    "plt.xlabel('Has Stage Fear')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Most Extroverts say NO to stage fear\n",
    "# Most Introverts say YES to stage fear\n",
    "# Stage fear is a key differentiator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 24: Drained After Socializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Shows relationship between feeling drained and Personality\n",
    "# This is a classic psychological trait that differentiates the two types\n",
    "plt.figure(figsize=(8, 4))\n",
    "pd.crosstab(clean_data['Drained_after_socializing'], clean_data['Personality']).plot(kind='bar')\n",
    "plt.title('Drained After Socializing by Personality')\n",
    "plt.xlabel('Feels Drained')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Personality')\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Extroverts mostly say NO - they get energy from socializing\n",
    "# Introverts mostly say YES - socializing drains their energy\n",
    "# This is a classic introvert/extrovert trait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 25: Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation requires numerical data, so encode categorical columns\n",
    "# map(): Replaces values based on a dictionary {old: new}\n",
    "data_encoded = clean_data.copy()\n",
    "data_encoded['Stage_fear'] = data_encoded['Stage_fear'].map({'Yes': 1, 'No': 0})\n",
    "data_encoded['Drained_after_socializing'] = data_encoded['Drained_after_socializing'].map({'Yes': 1, 'No': 0})\n",
    "data_encoded['Personality'] = data_encoded['Personality'].map({'Extrovert': 1, 'Introvert': 0})\n",
    "\n",
    "# Heatmap: Shows correlation between all pairs of variables\n",
    "# corr(): Calculates Pearson correlation (-1 to +1)\n",
    "# +1 = perfect positive correlation, -1 = perfect negative, 0 = no correlation\n",
    "# annot=True: Shows correlation values in each cell\n",
    "# cmap='coolwarm': Blue for negative, red for positive correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_encoded.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Features POSITIVELY correlated with Extrovert (value=1):\n",
    "#   - Social_event_attendance, Going_outside, Friends_circle_size, Post_frequency\n",
    "# Features NEGATIVELY correlated (means Introvert):\n",
    "#   - Time_spent_Alone, Stage_fear, Drained_after_socializing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 26: All Features Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar chart: Compare average values of all features side by side\n",
    "# groupby('Personality'): Groups data by Extrovert/Introvert\n",
    "# .mean(): Calculates average for each group\n",
    "means = clean_data.groupby('Personality')[num_cols].mean()\n",
    "\n",
    "# .T: Transpose (swap rows and columns) so features are on x-axis\n",
    "# This makes it easier to compare Extrovert vs Introvert for each feature\n",
    "means.T.plot(kind='bar', figsize=(10, 5), color=['coral', 'steelblue'])\n",
    "plt.title('Average Values: Extrovert vs Introvert')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Personality')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# INSIGHT: Clear pattern visible\n",
    "# Introverts: High time alone, low everything else\n",
    "# Extroverts: Low time alone, high everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualization Insights Summary\n",
    "\n",
    "**Extroverts tend to:**\n",
    "- Spend less time alone\n",
    "- Attend more social events\n",
    "- Go outside more often\n",
    "- Have larger friend circles\n",
    "- Post more on social media\n",
    "- NOT have stage fear\n",
    "- NOT feel drained after socializing\n",
    "\n",
    "**Introverts tend to:**\n",
    "- Spend more time alone\n",
    "- Attend fewer social events\n",
    "- Go outside less often\n",
    "- Have smaller friend circles\n",
    "- Post less on social media\n",
    "- Have stage fear\n",
    "- Feel drained after socializing\n",
    "\n",
    "**Best Predictor Features:**\n",
    "1. Time_spent_Alone (strongest)\n",
    "2. Social_event_attendance\n",
    "3. Stage_fear\n",
    "4. Drained_after_socializing\n",
    "\n",
    "### Next: Model Building"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
